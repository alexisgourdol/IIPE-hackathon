"""Module to extract text from reports of the Irish Department of Education.
Used, fixed and adapted some code from https://github.com/iiepdev/Inspection_Reports/blob/main/Ireland_Analysis.ipynb"""

import requests
import wget
import pandas as pd
from bs4 import BeautifulSoup
from pdfminer.high_level import extract_text


def scrape_reports_page(num_pages=142):
    """Returns a dataframe with metadata about each report.
    By default, limited to the first 142 pages (with PDF data on Feb'2020, to be adjusted eventuelly)"""

    # Records:    1 to   20 of 3871 ...
    webpage_root = "https://www.education.ie/en/Publications/Inspection-Reports-Publications/Whole-School-Evaluation-Reports-List/?pageNumber="

    # Create the column names for the final dataframe
    general_inspection_reports = pd.DataFrame(
        columns=[
            "Date",
            "School Roll No.",
            "County",
            "School Name",
            "School Level",
            "Inspection Type",
            "Subject",
            "URL",
        ]
    )

    # Scraping pages
    for x in range(1, num_pages + 1):
        ireland_webpage = requests.get(webpage_root + str(x))
        clean_ireland_webpage = BeautifulSoup(ireland_webpage.text, "lxml")
        inspection_reports = {}
        ID = 0
        table = clean_ireland_webpage.find("table", id="IRList")
        for p in table.find_all("tr"):
            if ID == 0:
                ID = ID + 1
                continue
            else:
                Date = (
                    p("td")[0].string[:2]
                    + "_"
                    + p("td")[0].string[3:5]
                    + "_"
                    + p("td")[0].string[6:]
                )
                SchoolRoll = p("td")[1].string
                County = p("td")[2].string
                SchoolName = p("td")[3].string
                SchoolLevel = p("td")[4].string
                InspectionType = p("td")[5].string
                Subject = p("td")[6].string
                URL = p("td")[7]("a")[0].attrs["href"][86:]
                inspection_reports[ID] = {
                    "Date": Date,
                    "School Roll No.": SchoolRoll,
                    "County": County,
                    "School Name": SchoolName,
                    "School Level": SchoolLevel,
                    "Inspection Type": InspectionType,
                    "Subject": Subject,
                    "URL": URL,
                }
                ID = ID + 1

        # Create the content of the final dataframe
        df_inspection_reports = pd.DataFrame.from_dict(
            inspection_reports, orient="index"
        )

        # Concatenate with the column names
        general_inspection_reports = pd.concat(
            [general_inspection_reports, df_inspection_reports]
        )

    return general_inspection_reports

    ##################################################################general_inspection_reports######################################################################
    # |    |       Date | School Roll No.   | County   | School Name     | School Level   | Inspection Type         | Subject   | URL                                |#
    # |---:|-----------:|:------------------|:---------|:----------------|:---------------|:------------------------|:----------|:-----------------------------------|#
    # |  0 | 27_01_2021 | 70660O            | Kildare  | Curragh Post... | Post Primary   | Whole School Evaluation | None      | 70660O_WSEMLLPP_14538_20200207.pdf |#
    # |  1 | 26_01_2021 | 61811I            | Wicklow  | St. Gerard's... | Post Primary   | Whole School Evaluation | None      | 61811I_WSEMLLPP_14721_20200331.pdf |#
    ##################################################################################################################################################################


def download_pdfs(df):
    """Input : a dataframe generated by scrape_reports_page()
    Returns : None, just downloads the pdfs"""

    General_InspectionReports = df
    PDFToConvert = []
    for index, row in General_InspectionReports.iterrows():
        DownloadURL = (
            "https://www.education.ie/en/Publications/Inspection-Reports-Publications/Whole-School-Evaluation-Reports-List/"
            + row["URL"]
        )
        FileName = "Reports\\" + row["School Roll No."] + "_" + row["Date"] + ".pdf"
        PDFToConvert.append("Reports\\" + row["School Roll No."] + "_" + row["Date"])
        print("Report " + row["School Roll No."] + " downloaded")
        wget.download(DownloadURL, FileName)

    return
