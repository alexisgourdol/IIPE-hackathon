"""Module to extract text from reports of the Irish Department of Education.
Used, fixed and adapted some code from https://github.com/iiepdev/Inspection_Reports/blob/main/Ireland_Analysis.ipynb"""

import os
import requests
import wget
import pandas as pd
from bs4 import BeautifulSoup
from pdfminer.high_level import extract_text
from IIPE.utils import find_2nd


def scrape_reports_page(num_pages=142):
    """Returns a dataframe with metadata about each report.
    By default, limited to the first 142 pages (with PDF data on Feb'2020, to be adjusted eventuelly)"""

    # Records:    1 to   20 of 3871 ...
    webpage_root = "https://www.education.ie/en/Publications/Inspection-Reports-Publications/Whole-School-Evaluation-Reports-List/?pageNumber="

    # Create the column names for the final dataframe
    general_inspection_reports = pd.DataFrame(
        columns=[
            "Date",
            "School Roll No.",
            "County",
            "School Name",
            "School Level",
            "Inspection Type",
            "Subject",
            "URL",
        ]
    )

    # Scraping pages
    for x in range(1, num_pages + 1):
        ireland_webpage = requests.get(webpage_root + str(x))
        clean_ireland_webpage = BeautifulSoup(ireland_webpage.text, "lxml")
        inspection_reports = {}
        ID = 0
        table = clean_ireland_webpage.find("table", id="IRList")
        for p in table.find_all("tr"):
            if ID == 0:
                ID = ID + 1
                continue
            else:
                Date = (
                    p("td")[0].string[:2]
                    + "_"
                    + p("td")[0].string[3:5]
                    + "_"
                    + p("td")[0].string[6:]
                )
                SchoolRoll = p("td")[1].string
                County = p("td")[2].string
                SchoolName = p("td")[3].string
                SchoolLevel = p("td")[4].string
                InspectionType = p("td")[5].string
                Subject = p("td")[6].string
                URL = p("td")[7]("a")[0].attrs["href"][86:]
                inspection_reports[ID] = {
                    "Date": Date,
                    "School Roll No.": SchoolRoll,
                    "County": County,
                    "School Name": SchoolName,
                    "School Level": SchoolLevel,
                    "Inspection Type": InspectionType,
                    "Subject": Subject,
                    "URL": URL,
                }
                ID = ID + 1

        # Create the content of the final dataframe
        df_inspection_reports = pd.DataFrame.from_dict(
            inspection_reports, orient="index"
        )

        # Concatenate with the column names
        general_inspection_reports = pd.concat(
            [general_inspection_reports, df_inspection_reports]
        )

    return general_inspection_reports

    ##################################################################general_inspection_reports######################################################################
    # |    |       Date | School Roll No.   | County   | School Name     | School Level   | Inspection Type         | Subject   | URL                                |#
    # |---:|-----------:|:------------------|:---------|:----------------|:---------------|:------------------------|:----------|:-----------------------------------|#
    # |  0 | 27_01_2021 | 70660O            | Kildare  | Curragh Post... | Post Primary   | Whole School Evaluation | None      | 70660O_WSEMLLPP_14538_20200207.pdf |#
    # |  1 | 26_01_2021 | 61811I            | Wicklow  | St. Gerard's... | Post Primary   | Whole School Evaluation | None      | 61811I_WSEMLLPP_14721_20200331.pdf |#
    ##################################################################################################################################################################


def download_pdfs(df):
    """Input : a dataframe generated by scrape_reports_page()
    Returns : None, just downloads the pdfs"""

    General_InspectionReports = df
    PDFToConvert = []
    for index, row in General_InspectionReports.iterrows():
        DownloadURL = (
            "https://www.education.ie/en/Publications/Inspection-Reports-Publications/Whole-School-Evaluation-Reports-List/"
            + row["URL"]
        )
        FileName = "Reports\\" + row["School Roll No."] + "_" + row["Date"] + ".pdf"
        PDFToConvert.append("Reports\\" + row["School Roll No."] + "_" + row["Date"])
        print("Report " + row["School Roll No."] + " downloaded")
        wget.download(DownloadURL, FileName)

    return PDFToConvert


def pdf_to_text(PDFToConvert, general_inspection_reports):
    """Converts into .txt files, each PDF returned by download_pdfs(scrape_reports_page())
    Adds a columns 'Key' to the general_inspection_reports dataframe"""
    ConvertionCategories = {
        "Properly processed": 0,
        "Not in text format": 0,
        "Cannot be processed": 0,
    }
    FilesProperlyConverted = {}
    FilesNotConverted = []

    for PDF in PDFToConvert:
        try:
            Text = extract_text(PDF + ".pdf")
            if len(Text) == 0:
                ConvertionCategories["Not in text format"] += 1
                print(PDF + " is not in text format")
            else:
                ConvertionCategories["Properly processed"] += 1
                Option1 = Text.find(
                    "WHOLE-SCHOOL EVALUATION – MANAGEMENT, LEADERSHIP AND LEARNING   Dates of inspection"
                )
                if Option1 != -1:
                    Text = Text[Option1:]
                Option2 = Text.find(
                    "WHOLE-SCHOOL EVALUATION – MANAGEMENT, LEADERSHIP AND LEARNING    Date of inspection"
                )
                if Option2 != -1:
                    Text = Text[Option2:]
                Option3 = Text.find(
                    "WHOLE-SCHOOL EVALUATION – MANAGEMENT, LEADERSHIP AND LEARNING  Dates of inspection"
                )
                if Option3 != -1:
                    Text = Text[Option3:]
                Option4 = Text.find(
                    "WHOLE-SCHOOL EVALUATION – MANAGEMENT, LEADERSHIP AND LEARNING Dates of inspection"
                )
                if Option4 != -1:
                    Text = Text[Option4:]
                Option5 = Text.find(
                    "Whole-School Evaluation – Management, Leadership and Learning Dates of inspection"
                )
                if Option5 != -1:
                    Text = Text[Option5:]
                Option6 = Text.find("Whole-School Evaluation Date of inspection")
                if Option6 != -1:
                    Text = Text[Option6:]
                if Text.find("An Roinn") == 1:
                    Text = Text[find_2nd(Text, "Dates of inspection") :]
                Option7 = Text.find("THE INSPECTORATE’S QUALITY CONTINUUM")
                if Option7 != -1:
                    Text = Text[: Option7 - 1]
                Option8 = Text.find(
                    "MEASTÓIREACHT SCOILE UILE – BAINISTÍOCHT, CEANNAIREACHT AGUS FOGHLAIM"
                )
                if Option8 != -1:
                    FilesNotConverted.append(PDF[8:])
                    print("Report " + PDF[8:] + " could not be processed")
                    continue
                FilesProperlyConverted[PDF] = {"Text": Text}
                file_to_write = PDF[8:] + ".txt"
                with open(
                    os.path.join("Reports", "Plain text", file_to_write),
                    "w",
                    errors="ignore",
                ) as output:
                    output.write(str(Text))
                print("Report " + PDF[8:] + " properly processed")
        except (KeyError, UnicodeEncodeError):
            ConvertionCategories["Cannot be processed"] = (
                ConvertionCategories["Cannot be processed"] + 1
            )
            FilesNotConverted.append(PDF[8:])
            print("Report " + PDF[8:] + " could not be processed")
            continue

    general_inspection_reports["Key"] = (
        general_inspection_reports["School Roll No."]
        + "_"
        + general_inspection_reports["Date"]
    )

    csv_to_save = "InspectionReports.csv"
    general_inspection_reports.to_csv(os.path.join("Reports", csv_to_save), index=False)
    for p in range(len(FilesNotConverted)):
        general_inspection_reports.drop(
            general_inspection_reports[
                general_inspection_reports.Key == FilesNotConverted[p]
            ].index,
            inplace=True,
        )

    csv_to_save_2 = "InspectionReports2.csv"
    general_inspection_reports.to_csv(
        os.path.join("Reports", csv_to_save_2), index=False
    )

    return general_inspection_reports
